{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6ecb8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "import numpy as np\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "315f5a5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5p/3492pb752gx28hp2p2vhhh9h0000gn/T/ipykernel_2163/730671058.py:42: FutureWarning: Passing 'suffixes' which cause duplicate columns {'2017_x'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  df = reduce(lambda left,right: pd.merge(left,right,on='Country', how='inner'), dfs)\n"
     ]
    }
   ],
   "source": [
    "# Load in all the datasets which we have to combine\n",
    "df_akamai = pd.read_csv('../raw_data/akamai_server_count.tsv', sep='\\t') # ['Service', 'Total', 'City', 'State', 'Country', 'Continent', '1', '0']\n",
    "df_akamai = df_akamai.groupby(['Country'], as_index=True).agg(Akai_Server_Count=('Total','sum'), Lat= ('1','mean'), Long=('0','mean'))\n",
    "\n",
    "df_internet_access = pd.read_csv('../raw_data/WORLD_BANK_INTERNET_ACCESS_DATA.csv') # ['Country Name', 'Country Code', 'Indicator Name', 'Indicator Code', years:'1960' - '2020']\n",
    "df_population = pd.read_csv('../raw_data/WORLD_BANK_POPULATION_DATA.csv') # ['Country Name', 'Country Code', 'Indicator Name', 'Indicator Code', years:'1960' - '2020']\n",
    "\n",
    "df_population = df_population.rename(columns={'Country Name': 'Country'})\n",
    "df_population = df_population.set_index('Country')\n",
    "df_population = df_population['2017']\n",
    "\n",
    "# We have to pivot these tables\n",
    "df_annual_co2_by_country = pd.read_csv('../raw_data/annual-co2-emissions-per-country.csv') # ['Entity', 'Code', 'Year', 'Annual CO2 emissions'] -> multiple entries for many years for each country\n",
    "df_annual_co2_emissions_per_capita = pd.read_csv('../raw_data/co-emissions-per-capita.csv') # ['Entity', 'Code', 'Year', 'Per capita CO2 emissions']\n",
    "df_energy = pd.read_csv('../raw_data/energy.csv') # ['Entity', 'Code', 'Year', 'Primary energy consumption (TWh)']\n",
    "df_share_renewables = pd.read_csv('../raw_data/share-electricity-renewables.csv') # ['Entity', 'Code', 'Year', 'Renewables (% electricity)']\n",
    "df_share_using_internet = pd.read_csv('../raw_data/share-of-individuals-using-the-internet.csv') # ['Entity', 'Code', 'Year', 'Individuals using the Internet (% of population)']\n",
    "\n",
    "def process_world_in_data_dataset(data, colName, year):\n",
    "  # Rename the entity columns so that they also say country\n",
    "  data = data.rename(columns={'Entity': 'Country'})\n",
    "  \n",
    "  # First we convert the world of data tables to have one row for each country and change the years to columns\n",
    "  # Set the index as the Entity (Country) -> and do the same for the other tables\n",
    "  data = data.pivot(index='Country', columns=\"Year\", values=colName)\n",
    "\n",
    "  # House work / clean up with the indices\n",
    "  data.rename_axis(None).reset_index(drop=True)\n",
    "\n",
    "  # Keep only the last 10 years of data for each dataset\n",
    "  # valid_years = [2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019]\n",
    "  data = data[year]\n",
    "  return data\n",
    "\n",
    "df_annual_co2_by_country = process_world_in_data_dataset(df_annual_co2_by_country, 'Annual CO2 emissions', 2017)\n",
    "df_annual_co2_emissions_per_capita = process_world_in_data_dataset(df_annual_co2_emissions_per_capita, 'Per capita CO2 emissions', 2017)\n",
    "df_energy = process_world_in_data_dataset(df_energy, 'Primary energy consumption (TWh)', 2017)\n",
    "df_share_renewables = process_world_in_data_dataset(df_share_renewables, 'Renewables (% electricity)', 2017)\n",
    "df_share_using_internet = process_world_in_data_dataset(df_share_using_internet, 'Individuals using the Internet (% of population)', 2017)\n",
    "\n",
    "dfs = [df_akamai, df_population, df_annual_co2_by_country, df_annual_co2_emissions_per_capita, df_energy, df_share_renewables, df_share_using_internet]\n",
    "df = reduce(lambda left,right: pd.merge(left,right,on='Country', how='inner'), dfs)\n",
    "df.columns = ['akamai_server_count', 'lat', 'long', 'population', 'annual_co2_by_country', 'annual_co2_emissions_per_capita', 'energy', 'share_renewables', 'share_using_internet']\n",
    "df.to_csv('../golden_source.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
